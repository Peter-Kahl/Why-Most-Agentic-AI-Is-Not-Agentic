# Why Most ‘Agentic AI’ Is Not Agentic

### Continuity, Authorship, and the Structural Conditions of Agency

---

by Peter Kahl, 2026-01-29

[![Generic badge](https://img.shields.io/badge/DOI-10.5281%2Fzenodo.18413863-blue.svg)](https://doi.org/10.5281/zenodo.18413863) [![Generic badge](https://img.shields.io/badge/ORCID-0009--0003--1616--4843-green.svg)](https://orcid.org/0009-0003-1616-4843)

## Abstract

Recent discourse increasingly describes advanced artificial intelligence systems as ‘agentic’. Planning-capable language models, autonomous workflows, and multi-agent architectures are said to exhibit agency insofar as they pursue goals, initiate actions, and coordinate behaviour over time. This article argues that such characterisations rest on a structural conflation. Drawing on a continuity-based account of agency, it shows that most systems labelled ‘agentic’ lack the conditions under which agency can arise at all. Agency, the article argues, is not a behavioural achievement but a structural response to continuity pressure: the need to preserve a unified locus of evaluative authority across incompatible future trajectories. Optimisation, planning, and coordination presuppose such unity; they do not generate it. Systems that are resettable, substitutable, or governed by externally specified evaluative standards may optimise effectively while lacking authorship of evaluative authority. Applying this criterion to contemporary AI architectures and governance practices, the article concludes that the principal danger lies not in machines becoming agents, but in attributing agency where continuity, authorship, and responsibility are structurally absent.

## Preprint Status

The manuscript is currently under review at a peer-reviewed journal. The version posted here is intended to make the argument publicly accessible during the review process and may differ from any final published version. Please cite this version if referring to the argument. Substantive revisions may be made in response to peer review.

## Keywords

agentic ai; artificial agency; continuity pressure; authorship; optimisation without agency; ai governance; fiduciary responsibility

## Download

- [Version v1](https://raw.githubusercontent.com/Peter-Kahl/Why-Most-Agentic-AI-Is-Not-Agentic/master/Why_Most_Agentic_AI_Is_Not_2026_01_29.pdf) ✅ _latest_

## Cite this work

- Kahl, Peter. 2026. “Why Most ‘Agentic AI’ Is Not Agentic: Continuity, Authorship, and the Structural Conditions of Agency.” Preprint. https://doi.org/10.5281/zenodo.18413863

## Publisher & Licence

Version v1 published in London by Peter Kahl, 2026-01-29.

© 2026 Peter Kahl. The author asserts the moral right to be identified as the author of this work and to object to its derogatory treatment. Licensed under Creative Commons BY-NC-ND 4.0. You may share this work for non-commercial purposes with attribution and without modification.\
Licence: https://creativecommons.org/licenses/by-nc-nd/4.0/ .